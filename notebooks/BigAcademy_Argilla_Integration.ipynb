{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì BigAcademy + Argilla Integration\n",
    "\n",
    "This notebook demonstrates the complete workflow for:\n",
    "1. Generating datasets with BigAcademy\n",
    "2. Uploading to Argilla for human review\n",
    "3. Downloading enhanced datasets\n",
    "4. Analyzing annotation quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add BigAcademy to path\n",
    "sys.path.append('/home/jovyan/work')\n",
    "\n",
    "# Import BigAcademy components\n",
    "from bigacademy.core.agent_profiles import AgentProfileManager\n",
    "from bigacademy.core.graph_db import GraphDB\n",
    "from bigacademy.generators.prompt_templates import PromptTemplateManager\n",
    "from bigacademy.generators.dataset_generator import DatasetGenerator\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"‚úÖ BigAcademy components imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 1. Generate Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load components\n",
    "agent_manager = AgentProfileManager(Path(\"/home/jovyan/work/configs/agents\"))\n",
    "template_manager = PromptTemplateManager(Path(\"/home/jovyan/work/configs/templates\"))\n",
    "\n",
    "# Load existing graph database (if available)\n",
    "db_path = Path(\"/home/jovyan/work/test_data/fastapi_minimal_architect.db\")\n",
    "if db_path.exists():\n",
    "    graph_db = GraphDB(db_path)\n",
    "    dataset_generator = DatasetGenerator(graph_db, template_manager)\n",
    "    \n",
    "    # Load agent profile\n",
    "    architect = agent_manager.get_profile(\"solution_architect\")\n",
    "    \n",
    "    print(f\"ü§ñ Loaded agent: {architect.name}\")\n",
    "    print(f\"üìö Graph database: {db_path}\")\nelse:\n",
    "    print(\"‚ö†Ô∏è  No existing graph database found. Run knowledge extraction first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate small dataset for demonstration\n",
    "if 'dataset_generator' in locals():\n",
    "    print(\"üéØ Generating sample dataset...\")\n",
    "    \n",
    "    dataset_batches = dataset_generator.generate_agent_dataset(\n",
    "        agent_profile=architect,\n",
    "        template_types=[\"question_answer\", \"code_review\"],\n",
    "        max_samples_per_template=3,\n",
    "        min_relevance_score=0.15\n",
    "    )\n",
    "    \n",
    "    # Save datasets\n",
    "    saved_files = dataset_generator.save_dataset_batches(dataset_batches, format=\"jsonl\")\n",
    "    \n",
    "    print(f\"‚úÖ Generated {len(dataset_batches)} batches\")\n",
    "    print(f\"üìÅ Saved files: {[f.name for f in saved_files]}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset generator not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê 2. Upload to Argilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload datasets to Argilla for review\n",
    "import subprocess\n",
    "\n",
    "if 'saved_files' in locals() and saved_files:\n",
    "    for file_path in saved_files:\n",
    "        print(f\"üì§ Uploading {file_path.name} to Argilla...\")\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run([\n",
    "                \"python\", \"/home/jovyan/work/scripts/upload_to_argilla.py\",\n",
    "                str(file_path),\n",
    "                \"--overwrite\"\n",
    "            ], capture_output=True, text=True, cwd=\"/home/jovyan/work\")\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(f\"‚úÖ Upload successful: {file_path.name}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Upload failed: {result.stderr}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error uploading {file_path.name}: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No dataset files to upload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® 3. Argilla UI Instructions\n",
    "\n",
    "Now you can:\n",
    "\n",
    "1. **Open Argilla UI**: http://localhost:6900\n",
    "2. **Login**: admin / bigacademy123\n",
    "3. **Review datasets** in the BigAcademy workspace\n",
    "4. **Rate samples** (excellent, good, fair, poor, terrible)\n",
    "5. **Edit responses** to improve quality\n",
    "6. **Add annotations** and feedback\n",
    "\n",
    "After reviewing, come back to download the enhanced dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• 4. Download Enhanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download enhanced dataset from Argilla\n",
    "dataset_name = \"solution_architect_question_answer\"  # Adjust based on your upload\n",
    "\n",
    "print(f\"üì• Downloading enhanced dataset: {dataset_name}\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run([\n",
    "        \"python\", \"/home/jovyan/work/scripts/download_from_argilla.py\",\n",
    "        dataset_name,\n",
    "        \"--analyze\",\n",
    "        \"--format\", \"jsonl\"\n",
    "    ], capture_output=True, text=True, cwd=\"/home/jovyan/work\")\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Download successful\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(f\"‚ùå Download failed: {result.stderr}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error downloading: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 5. Analyze Enhanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze enhanced dataset\n",
    "enhanced_files = list(Path(\"/home/jovyan/work/datasets\").glob(\"enhanced_*.jsonl\"))\n",
    "\n",
    "if enhanced_files:\n",
    "    latest_file = max(enhanced_files, key=lambda f: f.stat().st_mtime)\n",
    "    print(f\"üìä Analyzing: {latest_file.name}\")\n",
    "    \n",
    "    # Load enhanced dataset\n",
    "    enhanced_samples = []\n",
    "    with open(latest_file, 'r') as f:\n",
    "        for line in f:\n",
    "            enhanced_samples.append(json.loads(line))\n",
    "    \n",
    "    print(f\"üìà Loaded {len(enhanced_samples)} enhanced samples\")\n",
    "    \n",
    "    # Extract quality scores\n",
    "    quality_scores = []\n",
    "    annotations = []\n",
    "    \n",
    "    for sample in enhanced_samples:\n",
    "        metadata = sample.get('metadata', {})\n",
    "        quality_score = metadata.get('quality_score')\n",
    "        annotation = metadata.get('human_annotation')\n",
    "        \n",
    "        if quality_score:\n",
    "            quality_scores.append(quality_score)\n",
    "        if annotation:\n",
    "            annotations.append(annotation)\n",
    "    \n",
    "    print(f\"üéØ Annotated samples: {len(annotations)}\")\n",
    "    if quality_scores:\n",
    "        print(f\"üìä Average quality: {sum(quality_scores)/len(quality_scores):.2f}/5\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No enhanced datasets found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize quality distribution\n",
    "if 'annotations' in locals() and annotations:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Quality distribution\n",
    "    plt.subplot(1, 2, 1)\n",
    "    annotation_counts = pd.Series(annotations).value_counts()\n",
    "    plt.pie(annotation_counts.values, labels=annotation_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Quality Distribution')\n",
    "    \n",
    "    # Quality scores histogram\n",
    "    if quality_scores:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(quality_scores, bins=5, edgecolor='black', alpha=0.7)\n",
    "        plt.xlabel('Quality Score')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Quality Score Distribution')\n",
    "        plt.xticks(range(1, 6))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \nelse:\n",
    "    print(\"üìä No annotation data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ 6. Next Steps\n",
    "\n",
    "Your enhanced dataset is ready for training! \n",
    "\n",
    "**With BigTune:**\n",
    "```bash\n",
    "bigtune train --dataset=\"enhanced_solution_architect_*.jsonl\" \\\n",
    "              --base-model=\"llama-3.1-8b\" \\\n",
    "              --technique=\"lora\"\n",
    "```\n",
    "\n",
    "**Quality Insights:**\n",
    "- Use annotation analysis to improve BigAcademy templates\n",
    "- Focus on high-quality knowledge sources\n",
    "- Iterate on prompt engineering based on human feedback"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}